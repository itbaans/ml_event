{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":93147,"databundleVersionId":11094208,"sourceType":"competition"}],"dockerImageVersionId":30886,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:53:52.336161Z","iopub.execute_input":"2025-02-13T15:53:52.336369Z","iopub.status.idle":"2025-02-13T15:53:53.924655Z","shell.execute_reply.started":"2025-02-13T15:53:52.336348Z","shell.execute_reply":"2025-02-13T15:53:53.923768Z"}},"outputs":[{"name":"stdout","text":"/kaggle/input/dummy-competition-pro-battle/train_set_dummy.csv\n/kaggle/input/dummy-competition-pro-battle/test_set_dummy.csv\n/kaggle/input/dummy-competition-pro-battle/sample_solution_dummy.csv\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# Data manipulation and analysis\nimport pandas as pd\nimport numpy as np\n\n# Machine learning libraries\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import accuracy_score, precision_recall_curve, roc_auc_score\nfrom sklearn.impute import SimpleImputer\n\n\n# Specific models\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.model_selection import StratifiedKFold, cross_val_score\nfrom sklearn.metrics import accuracy_score, roc_auc_score","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:17:29.386633Z","iopub.execute_input":"2025-02-13T16:17:29.387044Z","iopub.status.idle":"2025-02-13T16:17:29.409126Z","shell.execute_reply.started":"2025-02-13T16:17:29.387013Z","shell.execute_reply":"2025-02-13T16:17:29.408235Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def load_and_prepare_data(filepath, sample_size=None):\n    \"\"\"\n    Load data with optional sampling for quick iterations\n    \n    Parameters:\n    filepath: str - Path to the dataset\n    sample_size: int or None - Number of samples to load (None for full dataset)\n    \n    Returns:\n    X, y - Features and target variables\n    \"\"\"\n    # Read the data\n    df = pd.read_csv(filepath)\n    \n    # Optional sampling for quick iterations\n    if sample_size is not None:\n        df = df.sample(n=sample_size, random_state=42)\n    \n    # Separate features and target\n    X = df.drop('target', axis=1)\n    y = df['target']\n    \n    return X, y\n\n# Usage example\nX, y = load_and_prepare_data('/kaggle/input/dummy-competition-pro-battle/train_set_dummy.csv')\nX = X.drop('row_id', axis=1)\n\n# For quick iterations with sample\nsX, sy = load_and_prepare_data('/kaggle/input/dummy-competition-pro-battle/train_set_dummy.csv', sample_size=1000)\nsX = sX.drop('row_id', axis=1)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:32:59.091154Z","iopub.execute_input":"2025-02-13T16:32:59.091589Z","iopub.status.idle":"2025-02-13T16:32:59.180647Z","shell.execute_reply.started":"2025-02-13T16:32:59.091558Z","shell.execute_reply":"2025-02-13T16:32:59.179178Z"}},"outputs":[],"execution_count":27},{"cell_type":"code","source":"def initialize_models():\n    \"\"\"\n    Initialize all models with their hyperparameters\n    Returns dictionary of model instances\n    \"\"\"\n    models = {\n        'xgboost': xgb.XGBClassifier(\n            n_estimators=100,\n            learning_rate=0.1,\n            max_depth=6,\n            random_state=42\n        ),\n        'random_forest': RandomForestClassifier(\n            n_estimators=100,\n            max_depth=10,\n            random_state=42\n        ),\n        'logistic': LogisticRegression(\n            max_iter=1000,\n            random_state=42\n        )\n    }\n    return models","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T15:58:23.438614Z","iopub.execute_input":"2025-02-13T15:58:23.439009Z","iopub.status.idle":"2025-02-13T15:58:23.444289Z","shell.execute_reply.started":"2025-02-13T15:58:23.438980Z","shell.execute_reply":"2025-02-13T15:58:23.442950Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Custom transformer for feature selection based on percentage NOTE: THIS IS JUST A EXAMPLE CLASS, YOU CAN MAKE YOUR OWN TAYLOARED TO YOUR OWN NEEDS. WE RECOMMEND TO USE AI ASSISTANT TO CREATE THIS\nclass PercentageFeatureSelector(BaseEstimator, TransformerMixin):\n    \"\"\"\n    Custom transformer that selects a percentage of features based on importance\n    \"\"\"\n    def __init__(self, feature_percentage=0.8):\n        self.feature_percentage = feature_percentage\n        self.selected_features = None\n    \n    def fit(self, X, y=None):\n        # Calculate feature importance using correlation with target\n        if isinstance(X, pd.DataFrame):\n            correlations = abs(X.corrwith(pd.Series(y)))\n            n_features = int(len(correlations) * self.feature_percentage)\n            self.selected_features = correlations.nlargest(n_features).index\n        return self\n    \n    def transform(self, X):\n        return X[self.selected_features] if isinstance(X, pd.DataFrame) else X\n\n# Create the main feature processing pipeline\ndef create_feature_pipeline():\n    \"\"\"\n    Creates a complete feature processing pipeline\n    \"\"\"\n    feature_pipeline = Pipeline([\n        ('feature_selector', PercentageFeatureSelector(feature_percentage=0.8)),\n        ('imputer', SimpleImputer(strategy='mean')),\n        ('scaler', MinMaxScaler())\n        # Add more transformers as needed\n    ])\n    return feature_pipeline","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:16:00.476791Z","iopub.execute_input":"2025-02-13T16:16:00.477166Z","iopub.status.idle":"2025-02-13T16:16:00.484001Z","shell.execute_reply.started":"2025-02-13T16:16:00.477139Z","shell.execute_reply":"2025-02-13T16:16:00.482594Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"#Training, this is using k-fold cross validation as it is best for providing the model performance. If the data is large you can use simple training too, change it as you need.\ndef train_and_evaluate(X, y, models, k=5, model_name='xgboost'):\n    \"\"\"\n    Train and evaluate multiple models using K-Fold cross-validation and the feature pipeline.\n    \n    Parameters:\n    X: Features DataFrame\n    y: Target Series\n    feature_pipeline: Sklearn Pipeline object\n    models: Dictionary of model instances\n    k: Number of folds for cross-validation (default=5)\n    \n    Returns:\n    Dictionary of results\n    \"\"\"\n    # Converting to DataFrame to use iloc\n    X_df = pd.DataFrame(X)\n    y_df = pd.Series(y)\n    skf = StratifiedKFold(n_splits=k, shuffle=True, random_state=42)\n    \n    results = {name: {'accuracy': [], 'auc_roc': []} for name in models.keys()}\n    \n    for train_idx, test_idx in skf.split(X, y):\n        X_train, X_test = X_df.iloc[train_idx], X_df.iloc[test_idx]\n        y_train, y_test = y_df.iloc[train_idx], y_df.iloc[test_idx]\n        \n        \n        for name, model in models.items():\n            # Train model\n            model.fit(X_train, y_train)\n            \n            # Predict\n            y_pred = model.predict(X_test)\n            y_proba = model.predict_proba(X_test)[:, 1]\n            \n            # Store metrics\n            results[name]['accuracy'].append(accuracy_score(y_test, y_pred))\n            results[name]['auc_roc'].append(roc_auc_score(y_test, y_proba))\n    \n    # Aggregate results\n    final_results = {\n        name: {\n            'accuracy_mean': np.mean(metrics['accuracy']),\n            'accuracy_std': np.std(metrics['accuracy']),\n            'auc_roc_mean': np.mean(metrics['auc_roc']),\n            'auc_roc_std': np.std(metrics['auc_roc']),\n        }\n        for name, metrics in results.items()\n    }\n    \n    return final_results, results[model_name]['auc_roc']","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:29:26.723971Z","iopub.execute_input":"2025-02-13T16:29:26.724249Z","iopub.status.idle":"2025-02-13T16:29:26.731028Z","shell.execute_reply.started":"2025-02-13T16:29:26.724228Z","shell.execute_reply":"2025-02-13T16:29:26.730057Z"}},"outputs":[],"execution_count":24},{"cell_type":"code","source":"# Initialize models\nmodels = initialize_models()\n\n# Create feature pipeline\nfeature_pipeline = create_feature_pipeline()\nX_transformed = feature_pipeline.fit_transform(X)\n\n# Train and evaluate\nresults, _ = train_and_evaluate(X_transformed, y, models)\n\n# Display results\nfor model_name, metrics in results.items():\n    print(f\"\\nResults for {model_name}:\")\n    for metric_name, value in metrics.items():\n        print(f\"{metric_name}: {value:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:33:11.264463Z","iopub.execute_input":"2025-02-13T16:33:11.264746Z","iopub.status.idle":"2025-02-13T16:33:19.273582Z","shell.execute_reply.started":"2025-02-13T16:33:11.264726Z","shell.execute_reply":"2025-02-13T16:33:19.270989Z"}},"outputs":[{"name":"stdout","text":"\nResults for xgboost:\naccuracy_mean: 0.5745\naccuracy_std: 0.0162\nauc_roc_mean: 0.6027\nauc_roc_std: 0.0181\n\nResults for random_forest:\naccuracy_mean: 0.5605\naccuracy_std: 0.0259\nauc_roc_mean: 0.5883\nauc_roc_std: 0.0253\n\nResults for logistic:\naccuracy_mean: 0.5030\naccuracy_std: 0.0344\nauc_roc_mean: 0.5107\nauc_roc_std: 0.0356\n","output_type":"stream"}],"execution_count":28},{"cell_type":"code","source":"#this will help you create solution files for submissions\ndef predict_and_save(test_file, feature_pipeline, model, output_file=\"solution.csv\"):\n    \"\"\"\n    Load the test file, preprocess features, predict probabilities, and save results.\n\n    Parameters:\n    test_file (str): Path to the test file (CSV format).\n    feature_pipeline (Pipeline): Pretrained feature processing pipeline.\n    model (object): Trained model with predict_proba method.\n    output_file (str): Name of the output CSV file (default: 'solution.csv').\n\n    Returns:\n    None\n    \"\"\"\n    # Load test data\n    test_data = pd.read_csv(test_file)\n\n    # Extract row IDs\n    row_ids = test_data.pop(\"row_id\")\n\n    # Transform features\n    X_test_processed = feature_pipeline.transform(test_data)\n\n    # Predict probabilities\n    y_pred_proba = model.predict_proba(X_test_processed)[:, 1]  # Probability for positive class\n\n    # Create and save solution file\n    submission = pd.DataFrame({\"row_id\": row_ids, \"target\": y_pred_proba})\n    submission.to_csv(output_file, index=False)\n    print(f\"Predictions saved to {output_file}\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:41:13.200110Z","iopub.execute_input":"2025-02-13T16:41:13.200438Z","iopub.status.idle":"2025-02-13T16:41:13.205153Z","shell.execute_reply.started":"2025-02-13T16:41:13.200413Z","shell.execute_reply":"2025-02-13T16:41:13.204346Z"}},"outputs":[],"execution_count":30},{"cell_type":"code","source":"predict_and_save('/kaggle/input/dummy-competition-pro-battle/test_set_dummy.csv', feature_pipeline, models['xgboost'])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-13T16:41:21.646644Z","iopub.execute_input":"2025-02-13T16:41:21.647023Z","iopub.status.idle":"2025-02-13T16:41:21.851296Z","shell.execute_reply.started":"2025-02-13T16:41:21.646974Z","shell.execute_reply":"2025-02-13T16:41:21.849436Z"}},"outputs":[{"name":"stdout","text":"Predictions saved to solution.csv\n","output_type":"stream"}],"execution_count":32}]}